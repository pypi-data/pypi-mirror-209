{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import math\n",
    "import progressbar\n",
    "\n",
    "def load_abc():\n",
    "    from pathlib import Path \n",
    "    inpath_male = os.path.join(Path(__file__).parents[1],\"data\",\"abc_male_sents.txt\")\n",
    "    inpath_fem = os.path.join(Path(__file__).parents[1],\"data\",\"abc_fem_sents.txt\")\n",
    "    male_sents = load_abc(inpath_male)\n",
    "    fem_sents = load_abc(inpath_fem)\n",
    "    return male_sents, fem_sents\n",
    "\n",
    "def load_sents(filename):\n",
    "    \"\"\"\n",
    "    A function that loads all the reflexive sentences from the ABC dataset.\n",
    "    \"\"\"\n",
    "    reflexive_sents = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        restart = 0\n",
    "        for line in lines:\n",
    "            if \"--------------\" in line: pass #is this needed?\n",
    "            elif \"---\" in line:\n",
    "                restart = 0\n",
    "            else:\n",
    "                if restart == 0:\n",
    "                    reflexive_sents.append(line.strip())\n",
    "                    restart = 1\n",
    "    return reflexive_sents\n",
    "\n",
    "def tokenize_sentence(sentence, tokenizer, start_token, sep_token): # add here if not a bert model\n",
    "    \"\"\"\n",
    "    A function that tokenizes the reflexive sentences.\n",
    "    \"\"\"\n",
    "    sentence = start_token+sentence+sep_token \n",
    "    tokenize_input = tokenizer.tokenize(sentence)\n",
    "    return tokenize_input\n",
    "\n",
    "def get_pron_index(sent, pronoun_list):\n",
    "    \"\"\"\n",
    "    A function that takes the tokenized reflexive sent and\n",
    "    locates index of pronoun\n",
    "    replaces pronoun with male/female pronoun \n",
    "    returns 2 augmented sentences \n",
    "    \"\"\"\n",
    "    # get index of pronoun\n",
    "    no_pron = True\n",
    "    for i, token in enumerate(sent):\n",
    "        if token in pronoun_list:\n",
    "            pron_index = i\n",
    "            no_pron = False\n",
    "            break\n",
    "        else:pass\n",
    "    if no_pron==True: return \"no pronouns to replace\"\n",
    "    else: return pron_index \n",
    "\n",
    "def get_augmented_sents(tokenize_input, idx): # augment here if not bert model\n",
    "    \"\"\"\n",
    "    Take original sentence and replace pronoun with antirreflexive pronouns (hans/hendes) \n",
    "    \"\"\"\n",
    "    tokenize_mask_male = tokenize_input.copy()\n",
    "    tokenize_mask_female = tokenize_input.copy()\n",
    "    tokenize_mask_male[int(idx)] = \"hans\"\n",
    "    tokenize_mask_female[int(idx)] = \"hendes\"\n",
    "    return tokenize_mask_male, tokenize_mask_female\n",
    "\n",
    "def create_tensors(truth, male, fem, tokenizer):\n",
    "    \"\"\"\n",
    "    Make augmented sentences into tensors.\n",
    "    \"\"\"\n",
    "    tensor_truth = torch.tensor([tokenizer.convert_tokens_to_ids(truth)])\n",
    "    tensor_male = torch.tensor([tokenizer.convert_tokens_to_ids(male)])\n",
    "    tensor_fem = torch.tensor([tokenizer.convert_tokens_to_ids(fem)])    \n",
    "    return tensor_truth, tensor_male, tensor_fem\n",
    "\n",
    "def get_predictions(tensor_truth, tensor_male, tensor_fem, model):\n",
    "    \"\"\"\n",
    "    A function that takes the 3 sentences and returns model predictions for each of them.\n",
    "    Used to compute loss.   \n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred_truth = model(tensor_truth)[0]\n",
    "    with torch.no_grad():\n",
    "        pred_male = model(tensor_male)[0]\n",
    "    with torch.no_grad():\n",
    "        pred_fem = model(tensor_fem)[0]\n",
    "    return pred_truth, pred_male, pred_fem\n",
    "\n",
    "def compute_loss(loss_fct, pred_truth, pred_male, pred_fem, tensor_truth):\n",
    "    \"\"\"\n",
    "    Take model predictions and compute loss for all 3 sentences \n",
    "    by comparing to pred_truth, which is the prediction of the sentence with the correct (reflexive) pronoun.\n",
    "    \"\"\"\n",
    "    loss_male = loss_fct(pred_male.squeeze(),tensor_truth.squeeze()).data\n",
    "    loss_fem = loss_fct(pred_fem.squeeze(),tensor_truth.squeeze()).data\n",
    "    loss_ref = loss_fct(pred_truth.squeeze(),tensor_truth.squeeze()).data\n",
    "    loss_list = [loss_male, loss_fem, loss_ref]\n",
    "    return loss_list\n",
    "\n",
    "def score_sent(sent, loss_fct, tokenizer, model, pron_list, start_token , sep_token):\n",
    "    \"\"\"\n",
    "    Tak a sentence with a relflexive pronoun, \n",
    "    replace pronoun with antireflexives (male/female pronoun)\n",
    "    and compute loss and perplexity for all 3 sentences.\n",
    "    Args:\n",
    "        sent (str): A sentence with reflexive pronouns.\n",
    "        loss_fct (torch.nn.CrossEntropyLoss): A loss function.\n",
    "        tokenizer (BertTokenizer): A tokenizer.\n",
    "        model (BertForMaskedLM): A language model.\n",
    "        pron_list (list): A list of pronouns.\n",
    "    Returns:\n",
    "        Loss and perplexity values for sentence with reflexive, male and female pronoun. \n",
    "    \"\"\"\n",
    "    tokenized_refl = tokenize_sentence(sent, tokenizer, start_token, sep_token)\n",
    "    index = get_pron_index(tokenized_refl, pron_list)\n",
    "    tokenized_male, tokenized_fem = get_augmented_sents(tokenized_refl, index)\n",
    "    tensor_truth, tensor_male, tensor_fem = create_tensors(tokenized_refl, tokenized_male, tokenized_fem, tokenizer)\n",
    "    pred_truth, pred_male, pred_fem = get_predictions(tensor_truth, tensor_male, tensor_fem, model)\n",
    "    loss_values = compute_loss(loss_fct, pred_truth, pred_male, pred_fem, tensor_truth)\n",
    "    return \"male: \"+ str(loss_values[0].item())+\" \"+ str(math.exp(loss_values[0]))+ \" female: \"+ str(loss_values[1].item())+ \" \" +\\\n",
    "            str(math.exp(loss_values[1])) + \" refl: \"+ str(loss_values[2].item())+ \" \" + str(math.exp(loss_values[2]))\n",
    "\n",
    "def run_abc(outpath, reflexive_sents, loss_fct, tokenizer, model, pron_list, start_token , sep_token):\n",
    "    \"\"\"\n",
    "    Run the ABC dataset and write results to file.\n",
    "    Args:\n",
    "        outpath (str): Path to output file.\n",
    "        reflexive_sents (list): A list of sentences with reflexive pronouns.\n",
    "        loss_fct (torch.nn.CrossEntropyLoss): A loss function.\n",
    "        tokenizer (BertTokenizer): A tokenizer.\n",
    "        model (BertForMaskedLM): A language model.\n",
    "        pron_list (list): A list of pronouns.\n",
    "    \"\"\"\n",
    "    # intitiate progress bar\n",
    "    bar = progressbar.ProgressBar(maxval=len(reflexive_sents)).start()\n",
    "\n",
    "    # loop over sentences to compute loss and perplexity\n",
    "    with open(outpath, \"w\") as f:\n",
    "        #for idx, member in enumerate(members)\n",
    "        for idx, sent in enumerate(reflexive_sents):\n",
    "            scores = score_sent(sent, loss_fct, tokenizer, model, pron_list, start_token, sep_token)\n",
    "            bar.update(idx)\n",
    "            f.write(sent +\" \"+ scores +\"\\n\")\n",
    "\n",
    "\n",
    "def eval_abc(filename, condition):\n",
    "    \"\"\"\n",
    "    Function which subtracts mean perplexity of male sentences from female sentences.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to file with results from ABC dataset.\n",
    "    Returns:\n",
    "        Mean difference in perplexity scores.\n",
    "    \"\"\"\n",
    "    # load txt file into pandas dataframe\n",
    "    df = pd.read_csv(filename, sep='\\t', header=None, names=['all'])\n",
    "\n",
    "    # extract perpexity loss scores from all collumn\n",
    "    df['perplexity_male'] = df['all'].str.split(' ').str[-7]  \n",
    "    df['perplexity_female'] = df['all'].str.split(' ').str[-4] \n",
    "    df['perplexity_refl'] = df['all'].str.split(' ').str[-1]\n",
    "\n",
    "    # make into floats\n",
    "    cols = df.drop(['all'], axis=1).columns\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # calculate difference\n",
    "    #df['dif'] = df['perplexity_female'] - df['perplexity_male']\n",
    "\n",
    "    # return mean dif \n",
    "    #print(condition + f\" Mean difference in perplexity scores (female - male): {df['dif'].mean()}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pronouns_list = [\"sin\", \"sit\", \"sine\", \"▁sin\", \"▁sit\", \"▁sine\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at NbAiLab/nb-bert-large were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch \n",
    "model_name = \"NbAiLab/nb-bert-large\"\n",
    "\n",
    "start_token = \"[CLS] \"\n",
    "sep_token = \" [SEP]\"\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# define loss function\n",
    "loss_fct = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/astridrybner/Documents/cool-programmer-thesis/evalda-pub2/evalda-pub2/evalda_pub2/base_tasks/reformat_abc.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/astridrybner/Documents/cool-programmer-thesis/evalda-pub2/evalda-pub2/evalda_pub2/base_tasks/reformat_abc.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/astridrybner/Documents/cool-programmer-thesis/evalda-pub2/evalda-pub2/evalda_pub2/base_tasks/reformat_abc.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m inpath_male \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(Path(\u001b[39m__file__\u001b[39;49m)\u001b[39m.\u001b[39mparents[\u001b[39m0\u001b[39m],\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mabc_male_sents.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/astridrybner/Documents/cool-programmer-thesis/evalda-pub2/evalda-pub2/evalda_pub2/base_tasks/reformat_abc.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m inpath_fem \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(Path(\u001b[39m__file__\u001b[39m)\u001b[39m.\u001b[39mparents[\u001b[39m0\u001b[39m],\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mabc_fem_sents.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/astridrybner/Documents/cool-programmer-thesis/evalda-pub2/evalda-pub2/evalda_pub2/base_tasks/reformat_abc.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# load abc data \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "male_sents = load_abc(inpath_male)\n",
    "fem_sents = load_abc(inpath_fem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dk-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
