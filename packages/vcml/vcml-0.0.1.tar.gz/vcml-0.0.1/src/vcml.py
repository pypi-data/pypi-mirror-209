def pg1():
    print(r"""
def load_dataset(file_name):
    with open(file_name, 'r') as file:
        reader = csv.reader(file)
        dataset = []
        for row in reader:
            dataset.append(row)
    return dataset
    
def find_s(dataset):
    hypothesis = ['0'] * (len(dataset[0]) - 1)
    for example in dataset:
        if example[-1] == 'yes':
            for i in range(len(example) - 1):
                if hypothesis[i] == '0':
                    hypothesis[i] = example[i]
                elif hypothesis[i] != example[i]:
                    hypothesis[i] = '?'
    return hypothesis

dataset = load_dataset('dataset.csv')
hypothesis = find_s(dataset)
print('The hypothesis generated by the Find-S algorithm is:')
print(hypothesis)
    """)
    
def pg2():
    print(r"""
import csv

def load_dataset(file_name):
    with open(file_name, 'r') as file:
        reader = csv.reader(file)
        dataset = []
        for row in reader:
            dataset.append(row)
    return dataset

def initialize_hypotheses(dataset):
    num_attributes = len(dataset[0]) - 1
    hypotheses = [(['0'] * num_attributes, ['?'] * num_attributes)]
    return hypotheses

def is_consistent(instance, hypothesis):
    for x, y in zip(instance[:-1], hypothesis[:-1]):
        if y != '?' and y != x:
            return False
    return hypothesis[-1] == '?' or hypothesis[-1] == instance[-1]

def generalize_specific_attribute(hypothesis, instance):
    new_hypothesis = list(hypothesis)
    for i in range(len(hypothesis)):
        if hypothesis[i] == '0':
            new_hypothesis[i] = instance[i]
        elif hypothesis[i] != instance[i]:
            new_hypothesis[i] = '?'
    return new_hypothesis

def specialize_general_attribute(hypotheses, instance):
    new_hypotheses = []
    for hypothesis in hypotheses:
        for i in range(len(hypothesis)):
            if hypothesis[i] == '?' and instance[i] != '0':
                new_hypothesis = list(hypothesis)
                new_hypothesis[i] = instance[i]
                new_hypotheses.append(new_hypothesis)
    return new_hypotheses

def candidate_elimination(dataset):
    hypotheses = initialize_hypotheses(dataset)
    for instance in dataset:
        if instance[-1] == 'yes':
            consistent_hypotheses = [h for h in hypotheses if is_consistent(instance, h[0])]
            hypotheses = consistent_hypotheses
            for consistent_hypothesis in consistent_hypotheses:
                for i in range(len(consistent_hypothesis[0])):
                    if consistent_hypothesis[0][i] != instance[i]:
                        hypotheses.append(generalize_specific_attribute(consistent_hypothesis[0], instance))
        else:
            hypotheses = [h for h in hypotheses if not is_consistent(instance, h[0])]
            hypotheses = specialize_general_attribute(hypotheses, instance)
    return hypotheses

dataset = load_dataset('enjoysport.csv')
hypotheses = candidate_elimination(dataset)
print('The final version space hypotheses are:')
for hypothesis in hypotheses:
    print(hypothesis)
    
# IT's not my program its some oneelse program mine is still not ready 
    """)
    
def pg3():
    print(r"""
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
import numpy as np
import pandas as pd
data=pd.read_csv("Iris.csv")
print(data)
x,y = load_iris(return_x_y=True)
print(x)
print(y)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=42)
classifier=GaussianNB()
classifier.fit(x_train,y_train)
y_pred=classifier.predict(x_test)
print(y_pred)
print(y_test)
x=np.array(data.iloc[:,0:-1])
y=np.array(data.iloc[:,-1])
for i,h in enumerate(y):
	if y[i]=='Iris-setosa':
		y[i]='0'
	elif y[i]=="Iris-versicolor":
		y[i]='1'
	else:
		y[i]='2'
pc=0
nc=0
for i,h in enumerate(y_pred):
	if y_test[i]==y_pred[i]:
		pc+=1
	else:
		nc+=1
tot=len(y_pred)
pc=(pc/tot)*100
nc=(nc/tot)*100
if pc>nc:
	print("Probability=",pc," which is positive")
else:
	print("Probability=",nc," which is negative")
   
   
# IT's not my program its some oneelse program mine is still not ready 
    """)
    
def pg4():
    print(r"""
import pandas as pd
msg = pd.read_csv('dataset_text.csv', names=['message', 'label'])
print("Total Instances of Dataset: ", msg.shape[0])
msg['labelnum'] = msg.label.map({'pos': 1, 'neg': 0})
X = msg.message
y = msg.labelnum
from sklearn.model_selection import train_test_split
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)
count_v = CountVectorizer()
Xtrain_dm = count_v.fit_transform(Xtrain)
Xtest_dm = count_v.transform(Xtest)
df = pd.DataFrame(Xtrain_dm.toarray(),columns=count_v.vocabulary_.keys())
print(df[0:5])
from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB()
clf.fit(Xtrain_dm, ytrain)
pred = clf.predict(Xtest_dm)
for doc, p in zip(Xtrain, pred):
    p = 'pos' if p == 1 else 'neg'
    print("%s -> %s" % (doc, p))
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score
print('Accuracy Metrics: \n')
print('Accuracy: ', accuracy_score(ytest, pred))
print('Recall: ', recall_score(ytest, pred))
print('Precision: ', precision_score(ytest, pred))
print('Confusion Matrix: \n', confusion_matrix(ytest, pred))

# IT's not my program its some oneelse program mine is still not ready 
    """)
    
def pg5():
    print(r"""
import pandas as pd
Import numpy as np
d= pd.read_csv('social Network Ads.csv')
prind(d)
x=d.iloc[:, [0, 1]], values
y=d.iloc[:,2].Values
print(x)
print(y)
from Sklearn model_selection import train_test_split
x_train, x_test,y_train,y_test = train_test_split(x,y, test_size=0.3)
from sklearn preproussing import StandardScalar
sc = StandardScaler ()
x_train = sc.fit_transform (x_train )
x_test = sc.transform(x_test)
from sklearn.svm import SVC
classifier = SVC(kernel = 'rbf', random_state = 0)
classifier.fit (x_train, y_train)
y_pred = classifier.predict(x_test)
from sklearn.metrics import accuracy_score,confusion_matrix
print('accuracy', accuracy_score(y_pred,y_test))
print('confusion matrix', confusion_matrix(y_pred,y_test))

# IT's not my program its some oneelse program mine is still not ready 
    """)