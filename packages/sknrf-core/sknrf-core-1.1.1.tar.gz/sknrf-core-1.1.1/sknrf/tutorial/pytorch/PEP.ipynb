{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib figures generated in the notebook inline with the rest of the script\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # Import NumPy for arrays and basic linear algebra\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt # Import PyPlot for basic plotting.\n",
    "import matplotlib as mpl # Import Matplotlib for advanced plotting.\n",
    "from mpl_toolkits.mplot3d import Axes3D # Import Matplotlib 3D Plots\n",
    "\n",
    "# from sknrf.model.settings import Settings\n",
    "# from sknrf.devices.signal import *\n",
    "# plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Numpy Array to PyTorch Tensors\n",
    "\n",
    "PyTorch is a python wrapping of the Torch C++ library performs the following tasks:\n",
    "\n",
    "1. Defines **torch.tensor**, a multi-dimensional array that can be moved between the CPU and GPU(s) that support CUDA.\n",
    "2. Defines **torch.autograd.function** that records a graph of all operations applied to one or more tensors and then performs automatic differentiation (backwards propagation) to determine the sensitivity of the input tensor to the output tensor.\n",
    "3. Defines **torch.nn** witch allows you to design a neural network that accept input tensors, graph multiple operations over hidden layers, outputing tensors that are tuned using an optimization strategy.\n",
    "4. Defines **torch.optim** with supports various optimization algorithms based on the first-order gradient, (learning rate) or the 2nd order hessian (momentum) of the output tensors.\n",
    "\n",
    "In a **neural network**, a **tensor** represents the state of individual net, while a **function** perform math operations to connect the state of one net to another. At the output, an **optimization loss function** calculates the difference between the predicted output and the expected output, and modifies the **tensors** in the hidden layers of the neural network to be used in the following itereation.\n",
    "\n",
    "A simplified class diagram of these components is presented below:\n",
    "![alt text](./images/PNG/PyTorch_Structure.png \"PyTorch Structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "#### Numpy Array\n",
    "np.array(data, dtype=None) → ndarray  # Create a new array\n",
    "nd.array.tolist() → list  # Convert numpy array to python list\n",
    "\n",
    "#### PyTorch Tensor\n",
    "torch.tensor(data, dtype=None, device=None, requires_grad=False) → Tensor  # Create a new tensor\n",
    "tensor.item()  # Convert tensor to python value if tensor value is a non-dimensional\n",
    "tensor.tolist()  # Convert tensor to  python list\n",
    "tensor.numpy() → numpy.ndarray # Convert tensor to numpy array\n",
    "torch.from_numpy(ndarray) → Tensor # Convert numpy array to tensor without copying data\n",
    "torch.as_tensor(data, dtype=None, device=None)   # Convert any data (list, ndarray, tensor) to a tensor\n",
    "\n",
    "#### Existing Envelope Signal\n",
    "signal.EnvelopeSignal(array, indep_map=IndepDict()) → Tensor  # Create a new signal\n",
    "\n",
    "#### Proposed Envelope Signal\n",
    "sig.esignal(data, dtype=None, device=None, requires_grad=True)\n",
    "\n",
    "Q. Does autograd allow us to implicitly track independent variables (using graphing)?\n",
    "A. singals are mainly altered using the following operations. (The purpose of indep_map).\n",
    "  - torch.index_select(input, dim, index, out=None) → Tensor, where index is an array/tensor of indices to extract along dim\n",
    "  - torch.masked_select(input, mask, out=None) → Tensor, where mask is a boolean array/tensor the same shape as input\n",
    "  - torch.narrow(input, dimension, start, length) → Tensor, where start length is similar to a slice operation with step = 1 and stop = start + length.\n",
    "  - torch.take(input, indices) → Tensor, where indicies is flat indexation of a 1D array/tensor\n",
    "  \n",
    "  **As long as these operations store a grad_func in the graph, indep_map should not be needed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Prove that we don't need indep_map:\n",
    "\n",
    "1. Create freq, time tensors\n",
    "2. Create a v1 tensor that implicilty stores a reference to freq, time tensors.\n",
    "3. Prove that freq and time can be accessed from v1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save/load functions are similar to arrays, but you must also specify the hardware device where the tensor is stored\n",
    "\n",
    "- torch.save(obj, f)\n",
    "- torch.load(f, **map_location=None**)\n",
    "\n",
    "where **map_location** is a function, torch.device, string or a dict specifying how to remap storage locations.\n",
    "A safe way to load a saved state on a different hardware configuration is to perform a two-step load:\n",
    "1. torch.load(.., map_location=’cpu’)\n",
    "2. load_state_dict()\n",
    "\n",
    "This allows you to load the state to the CPU and then move all of the tensors to the available GPUs after. It is considered to be a more stable way to save and load the state of your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Save and Load a tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limits\n",
    "torch.clamp(input, min, max, out=None) → Tensor provides a good way to maintain safe operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tolerences\n",
    "torch.trunc(input, out=None) → Tensor, truncates floating point values\n",
    "torch.allclose(self, other, rtol=1e-05, atol=1e-08, equal_nan=False) → bool, determines if tensors are almost equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Apply limits and check tolerances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.autograd.Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwards Propagation\n",
    "\n",
    "In a neural network, a **function** is a mathematical operation that connects the values of a set of **input tensors** to the values of a set of **output tensors**. Therefore the forward propagation should perform the following tasks:\n",
    "\n",
    "1. Calculate $outputs = f(inputs)$\n",
    "\n",
    "After calculating the final output of the neural network, the predicted error is calculated using a loss function and a derivative ($\\frac{d_{loss}}{d_{input}}$) will be used to update the value of each tensor input. The **differential chain rule** allows us to connect the derivative of function $f' = \\frac{df}{dg}$ to the derivative $g' = \\frac{dg}{dx}$ as follows:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "(f\\circ g)'&=(f'\\circ g)\\cdot g' \\\\\n",
    "(f(g(x))'&=f'(g(x))\\cdot g(x)' \\\\\n",
    "\\frac{df}{dx} &= \\frac{df}{dg} \\cdot \\frac{dg}{dx} \\\\\n",
    "\\frac{df}{dx}\\Big|_{x=c} &= \\frac{df}{dg}\\Big|_{g(c)} \\cdot \\frac{dg}{dx}\\Big|_{x=c}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Each subsequent equation is the same, however the addtional information added in later equations is describing the addional complexity of performing the chain rule (automatic differentiation) using finite difference (numerical derivatives) rather than analytical derivatives. For example, the numerical derivative ($\\frac{df}{dg}\\Big|_{g(c)}$) are only valid around a given point (${g(c)}$). This means that the partial derivative $\\frac{df}{dx}\\Big|_{x=c}$ is dependent on the partial derivative of future function evaluations that are unknown during forward propagation.\n",
    "\n",
    "The Function.forward mehtod controls forward propagation as follows:\n",
    "\n",
    "```python\n",
    "@staticmethod\n",
    "def forward(ctx, *args, **kwargs)\n",
    "```\n",
    "\n",
    "where ctx is a **context dictionary** that saves computations from the forward propagation that can be recalled when computing derivatives in the backwards propagation. Thus the forward propagation must perform the following tasks.\n",
    "\n",
    "1. Calculate $outputs = f(inputs)$\n",
    "2. Indentify which inputs/outputs tensors (nets in the neural network) that require derivatives.\n",
    "3. Record the non-differential computation results in **ctx** that will be recalled during backwards propagation.\n",
    "\n",
    "### Backwards Propagation\n",
    "\n",
    "The backward propagation method defined below calculates all of the partial derivatives that describe changes in the output as a function of changes in inputs and the values of hidden layers. \n",
    "```python\n",
    "@staticmethod\n",
    "def backward(ctx, *grad_outputs):\n",
    "```\n",
    "It is called back propagation because the chain rule demonstrates that these **numerical derivatives** depend on current value of the output tensors around which the grad_outputs are calculated. For example $\\frac{df}{dx}\\Big|_{x=c}$ is the function of this Function's anlaytical derivative $\\frac{dg}{dx}\\Big|_{x=c}$ (evaluated at $x=c$), but also the **grad_output** of the next function $\\frac{df}{dg}\\Big|_{g(c)}$.\n",
    "\n",
    "#### Example torch.autograd.Function\n",
    "\n",
    "Let's define an autograd.Function for the following operation:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f(x) &= e^x \\\\\n",
    "\\frac{df}{dx} &= e^x \\cdot\n",
    "\\end{aligned}$$\n",
    "\n",
    "```python\n",
    "class Exp(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i.exp()\n",
    "        ctx.save_for_backward(result)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        result, = ctx.saved_tensors\n",
    "        return grad_output * result\n",
    "```\n",
    "\n",
    "Even though is a very simple derivative, we save the value of $e**x$ in **ctx** so that we can re-use this value in the backward method (when the input x is no longer provided). We also note that the Exp does not need to know what the next function is in the chain, it only need a numerical approximation of its gradient (**grad_output**). The **chain rule** demonstrates that there is a way to separate the computation of numerical derivatives into separate functions that are implemented in the **backward** method of the torch.autograd.Function.\n",
    "\n",
    "\n",
    "#### Extension of Chain Rule to Higher-Order Derivatives\n",
    "\n",
    "Higher-order derivates are useful for nonlinear problems. Faà di Bruno's formula extends the chain rule to higher-order derivatives. \n",
    "\n",
    "$${d^n \\over dx^n} f(g(x))=\\sum \\frac{n!}{m_1!\\,1!^{m_1}\\,m_2!\\,2!^{m_2}\\,\\cdots\\,m_n!\\,n!^{m_n}}\\cdot f^{(m_1+\\cdots+m_n)}(g(x))\\cdot \\prod_{j=1}^n\\left(g^{(j)}(x)\\right)^{m_j}$$\n",
    "\n",
    "Several examples of higher-order derivatives are explictly provided below:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\frac{dy}{dx} & = \\frac{dy}{du} \\frac{du}{dx} \\\\\n",
    "\\frac{d^2 y }{d x^2} & = \\frac{d^2 y}{d u^2} \\left(\\frac{du}{dx}\\right)^2\n",
    "    + \\frac{dy}{du} \\frac{d^2 u}{dx^2} \\\\\n",
    "\\frac{d^3 y }{d x^3} & = \\frac{d^3 y}{d u^3} \\left(\\frac{du}{dx}\\right)^3\n",
    "    + 3 \\, \\frac{d^2 y}{d u^2} \\frac{du}{dx} \\frac{d^2 u}{d x^2}\n",
    "    + \\frac{dy}{du} \\frac{d^3 u}{d x^3} \\\\\n",
    "\\frac{d^4 y}{d x^4} & =\\frac{d^4 y}{du^4} \\left(\\frac{du}{dx}\\right)^4\n",
    "    + 6 \\, \\frac{d^3 y}{d u^3} \\left(\\frac{du}{dx}\\right)^2 \\frac{d^2 u}{d x^2}\n",
    "    + \\frac{d^2 y}{d u^2} \\left( 4 \\, \\frac{du}{dx} \\frac{d^3 u}{dx^3}\n",
    "    + 3 \\, \\left(\\frac{d^2 u}{dx^2}\\right)^2\\right)\n",
    "    + \\frac{dy}{du} \\frac{d^4 u}{dx^4}.\n",
    "\\end{aligned}$$\n",
    "\n",
    "An important observation is that the higher order derivatives are computed using lower order derivatives. This means that no new methods need to be defined in each Function in order to calculate higher-order derivatives.\n",
    "\n",
    "####  Extension of Chain Rule to Inverse Function Derivatives\n",
    "\n",
    "Suppose that $y = g(x)$ has an inverse function. Call its inverse function $f$ so that we have $x = f(y)$. If both **$g(x)$ and $f(y)$ are differentiable**, the derivative of the inverse function $f$ can solved in terms of $g'$:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f'(y) &= \\frac{1}{g'(f(y))} \\\\\n",
    "f' &= \\frac{1}{g'\\circ f} \\\\\n",
    "f' &= inv \\circ g'\\circ f\n",
    "\\end{aligned}$$\n",
    "\n",
    "While the Function definintion must explicitly define an **inverse** function $f$, no new methods need to be defined to calculate the inverse derivative $f'$. Therefore to formally support inverse function and their derivatives, we must add the following define the following properties in each Function.\n",
    "\n",
    "* inverse_func - some functions do not have an inverse\n",
    "* if (self.inverse_func is not None and self.derivative_exists and self.inverse_func.derivative_exists):\n",
    "\n",
    "The inverse derivative will define $\\frac{d_{in}}{d_{out}}$, which simply describes feedback in the system.\n",
    "\n",
    "#### Extension of Chain Rule to Higher Dimensions\n",
    "\n",
    "A first-order derivative of a multidimensional vector is a Jacobian. Thus the **chain rule** can be reformulated as follows:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "(f\\circ g)'&=(f'\\circ g)\\cdot g' \\\\\n",
    "\\nabla (f\\circ g) &= J_g^\\mathsf{T} \\cdot (\\nabla f \\circ g)\n",
    "\\end{aligned}$$\n",
    "\n",
    ",\n",
    "where $J_g$ denotes the Jacobian matrix of function g. \n",
    "\n",
    "$$\\mathbf J = \\begin{bmatrix}\n",
    "    \\dfrac{\\partial \\mathbf{g}}{\\partial x_1} & \\cdots & \\dfrac{\\partial \\mathbf{g}}{\\partial x_n} \\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "    \\dfrac{\\partial g_1}{\\partial x_1} & \\cdots & \\dfrac{\\partial g_1}{\\partial x_n}\\\\\n",
    "    \\vdots & \\ddots & \\vdots\\\\\n",
    "    \\dfrac{\\partial g_m}{\\partial x_1} & \\cdots & \\dfrac{\\partial g_m}{\\partial x_n} \\end{bmatrix}$$\n",
    "\n",
    "or, component-wise:\n",
    "\n",
    "$$\\mathbf J_{ij} = \\frac{\\partial f_i}{\\partial x_j}.$$\n",
    "\n",
    "This implies that extending the **chain-rule** to high-dimensional problems is accomplished by performin vector operations of dimension (i, j) rather than scalar operations. This is already taken care of by numpy vector math functions.\n",
    "\n",
    "### Proposal\n",
    "In theory we could extend the autograd.Function to support inverse derivative computational graphs. Some problems with this idea\n",
    "\n",
    "* Only One-to-One functions have an inverse.\n",
    "* Functions with multiple inputs do not have an inverse.\n",
    "* Some inverse functions may not have defined derivatives.\n",
    "\n",
    "This suggests that an inverse derivative computational graph could have broken links. An inverse autograd extension of the existing autograd library would not deal well with broken links in the graph because each autograd Function is a sandboxed class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.Module\n",
    "\n",
    "Describing relationships between operations is best left to how we define the structure of a neural network. For example, the forward/inverse propagation described above could be structured an a Bidirectional RNN (see **torch.nn.GRU**). The **torch.nn.Model** alows us to describe problems using a custom combination of **autograd.Funcrtions** and sub **nn.Models**.\n",
    "\n",
    "![alt text](./images/PNG/rnn-bidirectional.png \"Bi-directional RNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this diagram, the input signal ($s_0$) could propagate through a series of forward transforms ($A$), while the inverse signal ($s'_0$) could propagate through the inverse transforms ($A'$). In this case, the $Xi$ terms represent known/unknown impdedance stimuli, while the $Yi$ terms represent predicted currents. This could suggest that internal nodes, which are not measurable could be solved by training the network. \n",
    "\n",
    "A custom module can be defined as follows:\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "       x = F.relu(self.conv1(x))\n",
    "       return F.relu(self.conv2(x))\n",
    "```\n",
    "\n",
    "Notice that the **nn.Module** is a container of sub-Modules that can be organized in **nn.ModuleList**, or **nn.ModuleDict**. All Modules and sub-Modules inherit from **nn.Module**, which itself is a container that has the following notable methods.\n",
    "\n",
    "```python\n",
    "def buffers(self, recurse=True):\n",
    "        r\"\"\"Returns an iterator over module buffers. Tensors that are not part of the neural network\"\"\"\n",
    "        \n",
    "def parameters(self, recurse=True):\n",
    "        r\"\"\"Returns an iterator over module parameters. Wrapped tensors that are part of the neural network\"\"\"\n",
    "        \n",
    "def modules(self):\n",
    "        r\"\"\"Returns an iterator over all modules in the network.\"\"\"\n",
    "        \n",
    "def add_module(self, name, module):\n",
    "        r\"\"\"Adds a child module to the current module. Hence each module is a container\"\"\"\n",
    "        \n",
    "def state_dict(self, destination=None, prefix='', keep_vars=False):\n",
    "        r\"\"\"Returns a dictionary containing a whole state of the module.\"\"\"\n",
    "        \n",
    "def load_state_dict(self, state_dict, strict=True):\n",
    "        r\"\"\"Copies parameters and buffers from :attr:`state_dict` into this module and its descendants\"\"\"\n",
    "        \n",
    "def apply(self, fn):\n",
    "        r\"\"\"Applies ``fn`` recursively to every submodule\"\"\"\n",
    "        \n",
    "def train(self, mode=True):\n",
    "        r\"\"\"Sets the module in training mode.\"\"\"\n",
    "        \n",
    "def eval(self):\n",
    "        r\"\"\"Sets the module in evaluation mode.\"\"\"\n",
    "        \n",
    "def zero_grad(self):\n",
    "        r\"\"\"Sets gradients of all model parameters to zero.\"\"\"\n",
    "```\n",
    "\n",
    "Perhaps it would be a good idea to organize transforms in a **torch.nn.Sequential**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimizer is basically a loss function that takes the **nn.Module** tunable **parameters** as inputs and provides the next iteration using a **Optimizer.step()** method that is custom to every otimization type. The lr (learning rate) represents controls the first-order step, while momentum represents the second-order step. See an example below.\n",
    "\n",
    "```python\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "for input, target in dataset:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "Note that the momentum is similar to a 2nd-order solver, but not as powerful as it does not include a Hessian matrix. The Hessian accounts for mixed-parital derivatives, while the momentum factor just looks at second order with respect to each variable. THe learning rate uses the gradient to change the position of the weight, but the momentum changes the velocity of the weight. By not using a Hessian matrix, we do not need to change the behavior of autograd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. TypeCast(function) -> TypeCast(autograd.Function)\n",
    "    a. forward(signal, time, freq)\n",
    "    b. backward(signal, time, freq)\n",
    "    - This looks very complicated. I'm unable to forsea how a complicated data type could be transmitted between CPU/GPU/FPGA without stuff really going wrong. This data type needs to go between vastly different hw architectures.\n",
    "    - A workaround is to store the type information in Info() object inside AbstractModels which only exist on CPU\n",
    "    - Another workaround is to use capital letters for fs signals, lowercase for es signals (V1 vs V1)\n",
    "    - Another workaround is to store information in the variable name v1_ft, V1_ff\n",
    "    - Decision: Store type information in Info, use _ft, _ff, etc when there is a need to describe the doamin\n",
    "    \n",
    "2. DevicesModel(QObject) -> ErrorModel(nn.Module)\n",
    "    - devices = no change\n",
    "    - add_module(transforms = nn.Sequential())\n",
    "    - add_buffer(uncorrected_signals)\n",
    "    - add_parameter(correcte_signals, sweeps, time, freq)\n",
    "The ErrorModel is responsible for assigning signals to devices and to the database\n",
    "\n",
    "3. Measure(AbstractModel) -> Measure(AbstractModel)\n",
    "    self.data = open(database)\n",
    "    self.opt = optim.Optimizer()\n",
    "    self.loss_func = torch.nn.functional\n",
    "    for epoch in range(epochs):\n",
    "        for b_in, a_in, g_in in self.data:\n",
    "            b_out, a_out, g_out = self.model(xb)\n",
    "            loss = self.loss_func(b_out, b_goal) + loss_func(g_out, g_goal)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "    \n",
    "4. Transforms(AbstractModel) -> Transforms(nn.Module)\n",
    "    a. expected_type (esignal, fsignal, fssignal, etc)\n",
    "    a. forward(v, i, z) or forward(b, a, g)\n",
    "    b. inverse(v, i, z) or inverse(b, a, g)\n",
    "    \n",
    "5. Minimize(AbstractModel) -> optim.Optimizer\n",
    "    a). Do nothing.\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure\n",
    " - convert sweep_name: SweepPlan to sweep_name: Tensors\n",
    " - Register tensors in Error Model (current_measurement)\n",
    " - Register tensors in Database (entire sweep)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
