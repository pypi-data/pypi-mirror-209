# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/011_TaskStreaming.ipynb.

# %% auto 0
__all__ = ['logger', 'TaskPool', 'ExceptionMonitor', 'StreamExecutor', 'DynamicTaskExecutor', 'SequentialExecutor',
           'get_executor']

# %% ../../nbs/011_TaskStreaming.ipynb 1
import asyncio
import sys
from abc import ABC, abstractmethod

from asyncio import Task
from contextlib import asynccontextmanager
from typing import *

import anyio
from aiokafka import ConsumerRecord

from logging import Logger
from .logger import get_logger

# %% ../../nbs/011_TaskStreaming.ipynb 3
logger = get_logger(__name__)

# %% ../../nbs/011_TaskStreaming.ipynb 10
class TaskPool:
    def __init__(
        self,
        size: int = 100_000,
        on_error: Optional[Callable[[BaseException], None]] = None,
    ):
        self.size = size
        self.pool: Set[Task] = set()
        self.on_error = on_error
        self.finished = False

    async def add(self, item: Task) -> None:
        while len(self.pool) >= self.size:
            await asyncio.sleep(0)
        self.pool.add(item)
        item.add_done_callback(self.discard)

    def discard(self, task: Task) -> None:
        e = task.exception()
        if e is not None and self.on_error is not None:
            try:
                self.on_error(e)
            except Exception as ee:
                logger.warning(
                    f"Exception {ee} raised when calling on_error() callback: {e}"
                )

        self.pool.discard(task)

    def __len__(self) -> int:
        return len(self.pool)

    async def __aenter__(self) -> "TaskPool":
        self.finished = False
        return self

    async def __aexit__(self, *args: Any, **kwargs: Any) -> None:
        while len(self) > 0:
            await asyncio.sleep(0)
        self.finished = True

    @staticmethod
    def log_error(logger: Logger) -> Callable[[Exception], None]:
        def _log_error(e: Exception, logger: Logger = logger) -> None:
            logger.warning(f"{e=}")

        return _log_error

# %% ../../nbs/011_TaskStreaming.ipynb 14
class ExceptionMonitor:
    def __init__(self) -> None:
        self.exceptions: List[Exception] = []
        self.exception_found = False

    def on_error(self, e: Exception) -> None:
        self.exceptions.append(e)
        self.exception_found = True

    def _monitor_step(self) -> None:
        if len(self.exceptions) > 0:
            e = self.exceptions.pop(0)
            raise e

    async def __aenter__(self) -> "ExceptionMonitor":
        return self

    async def __aexit__(self, *args: Any, **kwargs: Any) -> None:
        while len(self.exceptions) > 0:
            self._monitor_step()
            await asyncio.sleep(0)

# %% ../../nbs/011_TaskStreaming.ipynb 17
class StreamExecutor(ABC):
    @abstractmethod
    async def run(  # type: ignore
        self,
        is_shutting_down_f: Callable[[], bool],
        produce_func: Callable[[], Awaitable[ConsumerRecord]],
        consume_func: Callable[[ConsumerRecord], Awaitable[None]],
    ) -> None:
        pass

# %% ../../nbs/011_TaskStreaming.ipynb 20
def _process_items_task(  # type: ignore
    consume_func: Callable[[ConsumerRecord], Awaitable[None]], task_pool: TaskPool
) -> Callable[
    [
        anyio.streams.memory.MemoryObjectReceiveStream,
        Callable[[ConsumerRecord], Awaitable[None]],
        bool,
    ],
    Coroutine[Any, Any, Awaitable[None]],
]:
    async def _process_items_wrapper(  # type: ignore
        receive_stream: anyio.streams.memory.MemoryObjectReceiveStream,
        consume_func: Callable[[ConsumerRecord], Awaitable[None]] = consume_func,
        task_pool=task_pool,
    ):
        async with receive_stream:
            async for msg in receive_stream:
                task: asyncio.Task = asyncio.create_task(consume_func(msg))  # type: ignore
                await task_pool.add(task)

    return _process_items_wrapper

# %% ../../nbs/011_TaskStreaming.ipynb 21
class DynamicTaskExecutor(StreamExecutor):
    def __init__(  # type: ignore
        self,
        throw_exceptions: bool = False,
        max_buffer_size=100_000,
        size=100_000,
    ):
        self.throw_exceptions = throw_exceptions
        self.max_buffer_size = max_buffer_size
        self.exception_monitor = ExceptionMonitor()
        self.task_pool = TaskPool(
            on_error=self.exception_monitor.on_error  # type: ignore
            if throw_exceptions
            else TaskPool.log_error(logger),
            size=size,
        )

    async def run(  # type: ignore
        self,
        is_shutting_down_f: Callable[[], bool],
        produce_func: Callable[[], Awaitable[ConsumerRecord]],
        consume_func: Callable[[ConsumerRecord], Awaitable[None]],
    ) -> None:
        send_stream, receive_stream = anyio.create_memory_object_stream(
            max_buffer_size=self.max_buffer_size
        )

        async with self.exception_monitor, self.task_pool:
            async with anyio.create_task_group() as tg:
                tg.start_soon(
                    _process_items_task(consume_func, self.task_pool), receive_stream
                )
                async with send_stream:
                    while not is_shutting_down_f():
                        if (
                            self.exception_monitor.exception_found
                            and self.throw_exceptions
                        ):
                            break
                        msgs = await produce_func()
                        for msg in msgs:
                            await send_stream.send(msg)

# %% ../../nbs/011_TaskStreaming.ipynb 30
def _process_items_coro(  # type: ignore
    consume_func: Callable[[ConsumerRecord], Awaitable[None]],
    throw_exceptions: bool,
) -> Callable[
    [
        anyio.streams.memory.MemoryObjectReceiveStream,
        Callable[[ConsumerRecord], Awaitable[None]],
        bool,
    ],
    Coroutine[Any, Any, Awaitable[None]],
]:
    async def _process_items_wrapper(  # type: ignore
        receive_stream: anyio.streams.memory.MemoryObjectReceiveStream,
        consume_func: Callable[[ConsumerRecord], Awaitable[None]] = consume_func,
        throw_exceptions: bool = throw_exceptions,
    ) -> Awaitable[None]:
        async with receive_stream:
            async for msg in receive_stream:
                try:
                    await consume_func(msg)
                except Exception as e:
                    if throw_exceptions:
                        raise e
                    else:
                        logger.warning(f"{e=}")

    return _process_items_wrapper

# %% ../../nbs/011_TaskStreaming.ipynb 31
class SequentialExecutor(StreamExecutor):
    def __init__(  # type: ignore
        self,
        throw_exceptions: bool = False,
        max_buffer_size=100_000,
    ):
        self.throw_exceptions = throw_exceptions
        self.max_buffer_size = max_buffer_size

    async def run(  # type: ignore
        self,
        is_shutting_down_f: Callable[[], bool],
        produce_func: Callable[[], Awaitable[ConsumerRecord]],
        consume_func: Callable[[ConsumerRecord], Awaitable[None]],
    ) -> None:
        send_stream, receive_stream = anyio.create_memory_object_stream(
            max_buffer_size=self.max_buffer_size
        )

        async with anyio.create_task_group() as tg:
            tg.start_soon(
                _process_items_coro(consume_func, self.throw_exceptions), receive_stream
            )
            async with send_stream:
                while not is_shutting_down_f():
                    msgs = await produce_func()
                    for msg in msgs:
                        await send_stream.send(msg)

# %% ../../nbs/011_TaskStreaming.ipynb 34
def get_executor(executor: Union[str, StreamExecutor, None] = None) -> StreamExecutor:
    if isinstance(executor, StreamExecutor):
        return executor
    elif executor is None:
        executor = "SequentialExecutor"
    return getattr(sys.modules["fastkafka._components.task_streaming"], executor)()  # type: ignore
