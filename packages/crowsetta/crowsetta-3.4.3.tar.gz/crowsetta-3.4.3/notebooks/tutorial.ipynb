{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. _tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial present beginners with an introduction to `crowsetta`. You can get the Jupyter notebook for this tutorial by going to https://github.com/NickleDave/crowsetta and clicking on the big green \"Clone or Download\" button on the right side of the screen. You can then find this notebook and others in the `crowsetta/notebooks/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Finding out what annotation formats are built in to** `crowsetta` **and getting some example data to work with**\n",
    "Since `crowsetta` is a tool to working with annotations of vocalizations, we need some audio files containing vocalizations that are annotated. In this case, birdsong.\n",
    "\n",
    "The first thing we need to do to work with any Python library is import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crowsetta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `formats` function to find out what formats are built in to Crowsetta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Annotation formats built in to Crowsetta: notmat, koumura'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowsetta.formats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download small example datasets of the built-in formats with the `fetch` function in the `data` module, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/13993349/cbinnotmat.tar.gz (8.6 MB)\n",
      "[........................................] 100.00000 - (  8.6 MB /   8.6 MB,   3.8 MB/s)   \n",
      "File saved as ./data/cbin-notmat.tar.gz.\n",
      "\n",
      "extracting ./data/cbin-notmat.tar.gz\n"
     ]
    }
   ],
   "source": [
    "crowsetta.data.fetch(format='notmat', destination_path='./data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we downloaded some `.cbin` audio files. Each `.cbin` file has an associated `.not.mat` file that contains the annotation.\n",
    "\n",
    "We use the `glob` function from the Python standard library to list those files. (`glob` gives you the full path to files that match a string pattern; `*` in the string below is a wildcard that will match zero or more characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/cbin-notmat/032312/gy6or6_baseline_230312_0819.190.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0819.190.cbin.not.mat',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0821.202.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0810.148.cbin.not.mat',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0808.138.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0816.179.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0817.183.cbin.not.mat',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0816.179.cbin.not.mat',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0813.163.cbin.not.mat',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0820.196.cbin.not.mat',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0811.159.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0817.183.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0809.141.cbin.not.mat',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0821.202.cbin.not.mat',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0810.148.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0813.163.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0820.196.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0809.141.cbin',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0811.159.cbin.not.mat',\n",
       " './data/cbin-notmat/032312/gy6or6_baseline_230312_0808.138.cbin.not.mat']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "glob('./data/cbin-notmat/032312/*.cbin*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(It doesn't matter much for our purposes, but ... files in the `.not.mat` annotation format are produced by a Matlab GUI, evsonganaly, and are used to annotate audio files produced by a Labview program for running behavioral experiments called EvTAF.)\n",
    "\n",
    "## **Using the** `Transcriber` **to load annotation files into a data type we can work with in Python**\n",
    "Now we want to use `crowsetta` to load the annotations into some **data type** that makes it easy to get what we want out of audio files. Python has several data types like a `list` or `dict` that make it easy to work with data; the data types that `crowsetta` gives us, `Sequence`s and `Segment`s, specifically make it easy to write clean code for working with annotation formats for birdsong and other vocalizations. \n",
    "\n",
    "First we need to get all the annotation files in some variable. We use `glob` again to do so, this time just getting the `.not.mat` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0819.190.cbin.not.mat\n",
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0810.148.cbin.not.mat\n",
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0817.183.cbin.not.mat\n",
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0816.179.cbin.not.mat\n",
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0813.163.cbin.not.mat\n",
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0820.196.cbin.not.mat\n",
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0809.141.cbin.not.mat\n",
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0821.202.cbin.not.mat\n",
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0811.159.cbin.not.mat\n",
      "./data/cbin-notmat/032312/gy6or6_baseline_230312_0808.138.cbin.not.mat\n"
     ]
    }
   ],
   "source": [
    "notmats = glob('./data/cbin-notmat/032312/*.not.mat')\n",
    "for notmat in notmats: print(notmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our annotation files in a variable, we use the `Transcriber` to load them.\n",
    "\n",
    "The `Transcriber` is a Python `class`, and we want to create a new `instance` of that class. You don't have to understand what that means, but you do have to know that before you can do anything with a `Transcriber`, you have to call the class, as if it were a function, and assign it to some variable, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scribe is an instance of a <class 'crowsetta.transcriber.Transcriber'>\n"
     ]
    }
   ],
   "source": [
    "scribe = crowsetta.Transcriber()\n",
    "print(\"scribe is an instance of a\", type(scribe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `scribe` with `methods` that we can use on our annotation files (methods are functions that \"belong\" to a class).\n",
    "\n",
    "### **Using the** `to_seq` **method to load annotation format files into** `Sequence`**s**\n",
    "\n",
    "The `to_seq` method loads each file into a `Sequence`, one of the data types that helps us work with the annotation. We call the method, passing our list of files as an argument for `file` and telling the `scribe` our `file_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = scribe.to_seq(file=notmats, file_format='notmat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each annotation file, we should have a `Sequence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotation files:  10\n",
      "Number of Sequences:  10\n",
      "The number of annotation files is equal to number of sequences.\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of annotation files: \", len(notmats))\n",
    "print(\"Number of Sequences: \", len(seq))\n",
    "if len(notmats) == len(seq):\n",
    "    print(\"The number of annotation files is equal to number of sequences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `Sequence` consists of some number of `Segment`s, i.e., a part of the sequence defined by an `onset` and `offset` that has a `label` associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first element of seq:  <Sequence with 54 segments>\n",
      "\n",
      "First two Segments of first Sequence:\n",
      "Segment(label='i', file='./data/cbin-notmat/032312/gy6or6_baseline_230312_0819.190.cbin', onset_s=0.435, offset_s=0.511, onset_ind=13924, offset_ind=16350)\n",
      "Segment(label='i', file='./data/cbin-notmat/032312/gy6or6_baseline_230312_0819.190.cbin', onset_s=0.583, offset_s=0.662, onset_ind=18670, offset_ind=21184)\n"
     ]
    }
   ],
   "source": [
    "print(\"first element of seq: \", seq[0])\n",
    "print(\"\\nFirst two Segments of first Sequence:\")\n",
    "for seg in seq[0].segments[0:2]: print(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using** `crowsetta` **data types to write clean code**\n",
    "\n",
    "Now that we have a `list` of `Sequence`s, we can `iterate` (loop) through it to get at our audio data in a clean, Pythonic way.\n",
    "\n",
    "Let's say we're interested in the mean amplitude of each type of syllable in an individual bird's song. How do we get that data into something in Python we can analyze? One approach would be to create a Python `dict` that maps the name of each syllable type to a list of the mean amplitudes of every occurrence of that syllable in our dataset.\n",
    "\n",
    "Something like this:\n",
    "```Python\n",
    "syl_amp_dict = {\n",
    "    'a': [0.01, 0.023, ..., 0.017],\n",
    "    'b': [0.03, 0.032, ..., 0.291],\n",
    "    ...,\n",
    "    'j': [0.07, 0.068, ..., 0.71],\n",
    "}\n",
    "```\n",
    "\n",
    "So to do that, we need to first figure out the unique types of syllables that will be the `keys` of our dictionary, `a`, `b`, ..., `n`.\n",
    "\n",
    "We'll `iterate` over all the `Sequence`s, and then in an inner loop, we'll `iterate` through all the `Segment`s in that `Sequence`, using the `label` property of the segment to figure out which syllable type we're looking at from this bird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syl_amp_dict {'a': [], 'b': [], 'c': [], 'd': [], 'e': [], 'f': [], 'g': [], 'h': [], 'i': [], 'j': [], 'k': []}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_labels = []\n",
    "for sequence in seq:\n",
    "    for segment in sequence.segments:\n",
    "        all_labels.append(segment.label)\n",
    "\n",
    "unique_labels = np.unique(all_labels)\n",
    "\n",
    "# now we make our dict,.\n",
    "# with some fancy Pythoning\n",
    "syl_amp_dict = dict(\n",
    "    zip(unique_labels,\n",
    "       [[] for _ in range(len(unique_labels))])\n",
    ")\n",
    "\n",
    "print(\"syl_amp_dict\", syl_amp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(There are more concise ways to do that, but doing it the way we did let us clearly see iterating through the `Segment`s and `Sequence`s.)\n",
    "\n",
    "Now we want to get the amplitude for each syllable. We'll take the amplitude from the audio waveform (instead of, say, making a spectrogram out of it and then getting an amplitude measure by summing power of every time bin in the spectrogram).\n",
    "\n",
    "Since the audio signal might be a bit noisy, we'll use a function, `smooth_data` (from the [`evfuncs`](https://github.com/soberlab/evfuncs) library) that takes the raw audio from a file, applies a bandpass filter, rectifies the signal, and then smooths it with a sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function smooth_data in module evfuncs.evfuncs:\n",
      "\n",
      "smooth_data(rawsong, samp_freq, freq_cutoffs=(500, 10000), smooth_win=2)\n",
      "    filter raw audio and smooth signal\n",
      "    used to calculate amplitude.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    rawsong : ndarray\n",
      "        1-d numpy array, \"raw\" voltage waveform from microphone\n",
      "    samp_freq : int\n",
      "        sampling frequency\n",
      "    freq_cutoffs: list\n",
      "        two-element list of integers, [low freq., high freq.]\n",
      "        bandpass filter applied with this list defining pass band.\n",
      "        If None, in which case bandpass filter is not applied.\n",
      "    smooth_win : integer\n",
      "        size of smoothing window in milliseconds. Default is 2.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    smooth : ndarray\n",
      "        1-d numpy array, smoothed waveform\n",
      "    \n",
      "    Applies a bandpass filter with the frequency cutoffs in spect_params,\n",
      "    then rectifies the signal by squaring, and lastly smooths by taking\n",
      "    the average within a window of size sm_win.\n",
      "    This is a very literal translation from the Matlab function SmoothData.m\n",
      "    by Evren Tumer. Uses the Thomas-Santana algorithm.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evfuncs\n",
    "help(evfuncs.smooth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence in seq:\n",
    "    cbin = sequence.file\n",
    "    raw_audio, samp_freq = evfuncs.load_cbin(cbin)\n",
    "    smoothed = evfuncs.smooth_data(raw_audio, samp_freq,\n",
    "                                   freq_cutoffs=(500, 10000))\n",
    "    for segment in sequence.segments:\n",
    "        smoothed_seg = smoothed[segment.onset_ind:segment.offset_ind]\n",
    "        mean_seg_amp = np.mean(smoothed_seg)\n",
    "        syl_amp_dict[segment.label].append(mean_seg_amp)\n",
    "\n",
    "mean_syl_amp_dict = {}\n",
    "for syl_label, mean_syl_amps_list in syl_amp_dict.items():\n",
    "    # get mean of means\n",
    "    mean_syl_amp_dict[syl_label] = np.mean(mean_syl_amps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of mean amplitude for syllable a: 208207.1240286356\n",
      "mean of mean amplitude for syllable b: 16679.46415410411\n",
      "mean of mean amplitude for syllable c: 1327150.5563241516\n",
      "mean of mean amplitude for syllable d: 510289.3285039273\n",
      "mean of mean amplitude for syllable e: 846590.5009779687\n",
      "mean of mean amplitude for syllable f: 522099.1725575389\n",
      "mean of mean amplitude for syllable g: 192993.6353244887\n",
      "mean of mean amplitude for syllable h: 167343.74232649207\n",
      "mean of mean amplitude for syllable i: 16903.56906972767\n",
      "mean of mean amplitude for syllable j: 3005979.1576137305\n",
      "mean of mean amplitude for syllable k: 170753.7788673711\n"
     ]
    }
   ],
   "source": [
    "for syl_label, mean_syl_amp in mean_syl_amp_dict.items():\n",
    "    print(f'mean of mean amplitude for syllable {syl_label}:',\n",
    "          mean_syl_amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now you've seen the basics of working with `crowsetta`. Get out there and analyze some vocalizations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
